version: '3.8'

services:
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  bot-instance-1:
    build: .
    env_file: .env
    environment:
      - INSTANCE_ID=instance-1
      - REDIS_HOST=redis
      - NVIDIA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    ports:
      - "8001:8000"
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./generated_images:/app/generated_images
      - ./flux-lora-adapters-00:/app/flux-lora-adapters-00
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 8gb
    ulimits:
      memlock: -1
      stack: 67108864

  # Optional: Only uncomment if you want to run multiple instances
  # bot-instance-2:
  #   build: .
  #   env_file: .env
  #   environment:
  #     - INSTANCE_ID=instance-2
  #     - REDIS_HOST=redis
  #     - NVIDIA_VISIBLE_DEVICES=0
  #     - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
  #   ports:
  #     - "8002:8000"
  #   depends_on:
  #     redis:
  #       condition: service_healthy
  #   volumes:
  #     - ./generated_images:/app/generated_images
  #     - ./flux-lora-adapters-00:/app/flux-lora-adapters-00
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
  #   shm_size: 8gb
  #   ulimits:
  #     memlock: -1
  #     stack: 67108864

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/certs:/etc/nginx/certs
    depends_on:
      - bot-instance-1
      # - bot-instance-2  # Uncomment if using multiple instances

volumes:
  redis-data: 